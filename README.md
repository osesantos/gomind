# ğŸ§  GoMind
[![Go](https://github.com/osesantos/gomind/actions/workflows/go.yml/badge.svg)](https://github.com/osesantos/gomind/actions/workflows/go.yml)

> A lightweight, modular MCP (Multi-Component Protocol) server written in Go, focused on **Private RAG (Retrieval-Augmented Generation)** powered by local LLMs and your personal data.

---

## âœ¨ What is GoMind?

**GoMind** is a **brain orchestrator** that sits between a user interface (like LibreChat) and multiple intelligent agents or plugins. It:
- Receives natural language questions
- Orchestrates calls to various data sources (Obsidian notes, local vector DBs, etc.)
- Uses **Hermes** as a message bus to communicate with agents
- Assembles the full context and sends it to a local LLM (via Ollama)
- Returns the response to the user

Think of it as a **LangChain killer** â€” 100% private, no dependencies, fast and fully owned by you.

---

## ğŸ§© Architecture Overview

```text
[LibreChat or CLI]
        â”‚
        â–¼
     [ GoMind ]  â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†â†
        â”‚                               â”‚
        â”‚                               â”‚
        â”œâ”€â”€â†’ Receives natural language question (e.g. "What is GoMind?")
        â”‚                               â”‚
        â”œâ”€â”€â†’ Parses question and identifies required data sources
        â”‚                               â”‚
        â”‚                               â”œâ”€â”€â†’ [Obsidian Reader Agent] (MCP Core)
        â”‚                               â”‚
        â”‚                               â”œâ”€â”€â†’ [Vector Search Agent] (MCP Core)
        â”‚                               â”‚
        â”‚                               â””â”€â”€â†’ [Other Agents]
     (MCP Core)                         â”‚
        â”‚                               â”‚
        â”œâ”€â”€â†’ Publishes requests via Hermes ("query.obsidian", "query.search", ...)
        â”‚                               â”‚
        â”œâ”€â”€â† Receives responses via Hermes (with correlation ID)
        â”‚                               â”‚
        â””â”€â”€â†’ Assembles context + sends prompt to LLM (Ollama)
        â”‚
        â–¼
    [ Local Response ]
```

---

## ğŸ”§ Tech Stack

- **Go 1.22+**
- **Hermes** (lightweight pub/sub message bus)
- **Ollama** (local LLM runner, e.g. Mistral)
- **Meilisearch or Chroma** (for vector search)
- **Markdown file support** (e.g. Obsidian vaults)
- **JSON-based message protocol** with correlation ID

---

## ğŸ“¦ Features

- ğŸ§  Private RAG from your local knowledge base
- ğŸª Plugin-based architecture using Hermes
- âš¡ Fast and lightweight (no LangChain or Python overhead)
- ğŸ§° Extensible with `hermes-go-sdk` for writing new agents
- â±ï¸ Timeouts, fan-out/fan-in orchestration, modular pipeline

---

## ğŸš§ Status

> MVP in progress â€” building core functionality first:  
> âœ… Ollama connector  
> âœ… Obsidian reader agent  
> âœ… Basic message bus with Hermes  
> ğŸ”œ Plugin protocol schema + timeout management  
> ğŸ”œ Agent discovery + CLI mode

---

## ğŸš€ Getting Started

```bash
git clone https://github.com/osesantos/gomind
cd gomind
go run src/main.go
```

```bash
# Test with curl
curl -X POST http://localhost:4433/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What is GoMind?"}'

```

Make sure you have:
- Hermes running (or embedded mode)
- Ollama installed and serving a model (e.g. `ollama run mistral`)
- Some markdown notes to test against

---

## ğŸ“œ License

MIT â€” made with â¤ï¸ and caffeine.

---

## ğŸ™Œ Credits

Inspired by:
- LangChain (but better)
- Personal RAG workflows
- Modular AI design

Built by [osesantos](https://github.com/osesantos)
